{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part1 图谱抽取\n",
    "> [1]【必做】根据实验一中提供的电影ID列表，匹配获得Freebase中对应的实体（共578个可匹配实体）。\n",
    "> \n",
    "> [2]【必做】以578个可匹配实体为起点，通过三元组关联，提取一跳可达的全部实体，以形成新的起点集合。重复若干次该步骤，并将所获得的全部实体及对应三元组合并为用于下一阶段实验的知识图谱子图。\n",
    ">\n",
    "> [3]【选做】根据实验二提供的电影Tag信息，在图谱中添加一类新实体（Tag类），并建立其与电影实体的三元组，以充实电影的语义信息。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 获得初始电影实体"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1200 ['1292052', '1295644', '1292720', '3541415', '3742360']\n",
      "578 [('1291544', 'm.03177r'), ('1291545', 'm.027pfg'), ('1291546', 'm.01d1_s'), ('1291550', 'm.053xlz'), ('1291552', 'm.017jd9')]\n",
      "578 ['m.09_33n', 'm.0680y4', 'm.027m67', 'm.025cm9', 'm.02pxxg7']\n"
     ]
    }
   ],
   "source": [
    "# 读取 id 列表\n",
    "import csv\n",
    "movie_ids = []\n",
    "with open('../data/Movie_id.csv', 'r') as f:\n",
    "    reader = csv.reader(f)\n",
    "    for row in reader:\n",
    "        movie_ids.append(row[0])\n",
    "print(len(movie_ids), movie_ids[:5])\n",
    "\n",
    "# 读取映射表，txt 文件\n",
    "entity_movie_map = {}\n",
    "with open('../data/douban2fb.txt', 'r') as f:\n",
    "    for line in f:\n",
    "        # 格式不统一，有的 \\t 有的空格\n",
    "        # 将 \\t 替换成空格\n",
    "        line = line.replace('\\t', ' ')\n",
    "        line = line.strip().split(' ')\n",
    "        entity_movie_map[line[0]] = line[1]\n",
    "print(len(entity_movie_map), list(entity_movie_map.items())[:5])\n",
    "\n",
    "# 得到实体 ID\n",
    "entity_ids = set()\n",
    "for movie_id in movie_ids:\n",
    "    # 只保留有映射的\n",
    "    if movie_id in entity_movie_map:\n",
    "        entity_ids.add(entity_movie_map[movie_id])\n",
    "print(len(entity_ids), list(entity_ids)[:5])\n",
    "# 保存到 pkl 文件\n",
    "import pickle\n",
    "with open('../result/entity_ids0.pkl', 'wb') as f:\n",
    "    pickle.dump(entity_ids, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 定义生成子图的函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm as tqdm\n",
    "import gzip\n",
    "\n",
    "# 以 entity_ids 为起点生成一跳子图，保存到 des.gz 文件中\n",
    "def Get1StepSubGraph(entity_ids, des='graph1step'):\n",
    "    with gzip.open('../result/' + des + '.gz', 'wb') as ans:\n",
    "        with gzip.open('../data/freebase_douban.gz', 'rb') as f:\n",
    "            for line in tqdm(f, total=395577070):\n",
    "                line = line.strip()\n",
    "                triplet = line.decode().split('\\t')[:3]\n",
    "                # 排除前缀不是 http://rdf.freebase.com/ns/ 的实体\n",
    "                if (triplet[0][:28] != '<http://rdf.freebase.com/ns/') \\\n",
    "                    or (triplet[1][:28] != '<http://rdf.freebase.com/ns/') \\\n",
    "                    or (triplet[2][:28] != '<http://rdf.freebase.com/ns/'):\n",
    "                    continue\n",
    "                # 保存起点在 entity_ids 中的三元组\n",
    "                if triplet[0][28:-1] in entity_ids:\n",
    "                    ans.write(line + b'\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 获得一跳子图"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# 获得起始实体 ID\n",
    "entity_ids0 = set()\n",
    "with open('../result/entity_ids0.pkl', 'rb') as f:\n",
    "    entity_ids0 = pickle.load(f)\n",
    "# 如果已经提取过，就不用再提取了\n",
    "if not os.path.exists('../result/graph1step.gz'):\n",
    "    Get1StepSubGraph(entity_ids0)\n",
    "# 大约耗时 10 分钟"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 定义筛选子图的函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 从 triplets 中筛选出度大于 limit 的实体\n",
    "def Select(entity_ids0, triplets, entity_limit=20, relation_limit=50):\n",
    "    entity_count = {}\n",
    "    relation_count = {}\n",
    "    # 计数\n",
    "    for triplet in triplets:\n",
    "        if triplet[0] not in entity_count:\n",
    "            entity_count[triplet[0]] = 0\n",
    "        entity_count[triplet[0]] += 1\n",
    "        if triplet[1] not in relation_count:\n",
    "            relation_count[triplet[1]] = 0\n",
    "        relation_count[triplet[1]] += 1\n",
    "        if triplet[2] not in entity_count:\n",
    "            entity_count[triplet[2]] = 0\n",
    "        entity_count[triplet[2]] += 1\n",
    "    # 筛选\n",
    "    ans = []\n",
    "    for triplet in triplets:\n",
    "        # 要不就是在 entity_ids0 中，要不就是度大于 limit\n",
    "        if (triplet[0] in entity_ids0 or entity_count[triplet[0]] > entity_limit) \\\n",
    "        and (relation_count[triplet[1]] > relation_limit) \\\n",
    "        and (triplet[2] in entity_ids0 or entity_count[triplet[2]] > entity_limit):\n",
    "            ans.append(triplet)\n",
    "    return ans"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 筛选一跳子图"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "118773 [['m.012x63', 'type.object.type', 'base.type_ontology.inanimate'], ['m.012x63', 'film.film.genre', 'm.03k9fj'], ['m.012x63', 'film.film.dubbing_performances', 'm.0p7zw8x'], ['m.012x63', 'film.film.distributors', 'm.0zcrwbm'], ['m.012x63', 'film.film.dubbing_performances', 'm.0p7zxhh']]\n",
      "18204 18396\n",
      "18204 18204\n",
      "750 ['m.09_33n', 'm.0680y4', 'm.03h64', 'm.0cq22n0', 'm.024qqx']\n",
      "578 ['m.09_33n', 'm.0680y4', 'm.027m67', 'm.025cm9', 'm.02pxxg7']\n",
      "750 ['m.09_33n', 'm.0680y4', 'm.03h64', 'm.0cq22n0', 'm.024qqx']\n"
     ]
    }
   ],
   "source": [
    "entity_ids0 = set()\n",
    "with open('../result/entity_ids0.pkl', 'rb') as f:\n",
    "    entity_ids0 = pickle.load(f)\n",
    "# 读取一跳子图\n",
    "triplets = []\n",
    "with gzip.open('../result/graph1step.gz', 'rb') as f:\n",
    "    for line in f:\n",
    "        line = line.strip()\n",
    "        triplet = line.decode().split('\\t')[:3]\n",
    "        triplet = [triplet[0][28:-1], triplet[1][28:-1], triplet[2][28:-1]]\n",
    "        triplets.append(triplet)\n",
    "print(len(triplets), triplets[:5])\n",
    "\n",
    "# 筛选至收敛\n",
    "triplets_selected = Select(entity_ids0, triplets)\n",
    "while len(triplets_selected) < len(triplets):\n",
    "    triplets = triplets_selected\n",
    "    triplets_selected = Select(entity_ids0, triplets)\n",
    "    print(len(triplets_selected), len(triplets))\n",
    "\n",
    "# 保存 ID\n",
    "entity_ids = set()\n",
    "for triplet in triplets_selected:\n",
    "    entity_ids.add(triplet[0])\n",
    "    entity_ids.add(triplet[2])\n",
    "print(len(entity_ids), list(entity_ids)[:5])\n",
    "# 保存到 pkl 文件\n",
    "with open('../result/entity_ids1.pkl', 'wb') as f:\n",
    "    pickle.dump(entity_ids, f)\n",
    "\n",
    "# 验证是否包含 entity_ids0\n",
    "entity_ids0 = set()\n",
    "with open('../result/entity_ids0.pkl', 'rb') as f:\n",
    "    entity_ids0 = pickle.load(f)\n",
    "print(len(entity_ids0), list(entity_ids0)[:5])\n",
    "entity_ids1 = set()\n",
    "with open('../result/entity_ids1.pkl', 'rb') as f:\n",
    "    entity_ids1 = pickle.load(f)\n",
    "print(len(entity_ids1), list(entity_ids1)[:5])\n",
    "for entity_id in entity_ids0:\n",
    "    if entity_id not in entity_ids1:\n",
    "        print(entity_id, 'not in entity_ids1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 获得两跳子图"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 获取起始 ID\n",
    "entity_ids1 = set()\n",
    "with open('../result/entity_ids1.pkl', 'rb') as f:\n",
    "    entity_ids1 = pickle.load(f)\n",
    "if not os.path.exists('../result/graph2step.gz'):\n",
    "    Get1StepSubGraph(entity_ids1, des='graph2step')\n",
    "# 大约耗时 15 分钟"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 筛选两跳子图"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 获取起始 ID\n",
    "entity_ids0 = set()\n",
    "with open('../result/entity_ids0.pkl', 'rb') as f:\n",
    "    entity_ids0 = pickle.load(f)\n",
    "if not os.path.exists('../result/graph2step_selected.gz'):\n",
    "    # 读取两跳子图\n",
    "    with gzip.open('../result/graph2step.gz', 'rb') as f:\n",
    "        entity_count = {}\n",
    "        relation_count = {}\n",
    "        # 计数\n",
    "        for line in tqdm(f, total=104698451):\n",
    "            line = line.strip()\n",
    "            triplet = line.decode().split('\\t')[:3]\n",
    "            triplet = [triplet[0][28:-1], triplet[1][28:-1], triplet[2][28:-1]]\n",
    "            if triplet[0] not in entity_count:\n",
    "                entity_count[triplet[0]] = 0\n",
    "            entity_count[triplet[0]] += 1\n",
    "            if triplet[1] not in relation_count:\n",
    "                relation_count[triplet[1]] = 0\n",
    "            relation_count[triplet[1]] += 1\n",
    "            if triplet[2] not in entity_count:\n",
    "                entity_count[triplet[2]] = 0\n",
    "            entity_count[triplet[2]] += 1\n",
    "        \n",
    "        f.seek(0)\n",
    "        remove_entity = set()\n",
    "        remove_relation = set()\n",
    "        # ！只能边读边筛选，不然内存会爆掉\n",
    "        for line in tqdm(f, total=104698451):\n",
    "            line = line.strip()\n",
    "            triplet = line.decode().split('\\t')[:3]\n",
    "            triplet = [triplet[0][28:-1], triplet[1][28:-1], triplet[2][28:-1]]\n",
    "            # 过滤出现大于 20000 的实体\n",
    "            if entity_count[triplet[0]] > 20000:\n",
    "                remove_entity.add(triplet[0])\n",
    "            if entity_count[triplet[2]] > 20000:\n",
    "                remove_entity.add(triplet[2])\n",
    "            # 过滤出现小于 50 的关系\n",
    "            if relation_count[triplet[1]] <= 50:\n",
    "                remove_relation.add(triplet[1])\n",
    "        print(len(remove_entity), len(remove_relation))\n",
    "        \n",
    "        f.seek(0)\n",
    "        for line in tqdm(f, total=104698451):\n",
    "            line = line.strip()\n",
    "            triplet = line.decode().split('\\t')[:3]\n",
    "            triplet = [triplet[0][28:-1], triplet[1][28:-1], triplet[2][28:-1]]\n",
    "            if triplet[0] in remove_entity or triplet[1] in remove_relation or triplet[2] in remove_entity:\n",
    "                continue\n",
    "            triplets.append(triplet)\n",
    "    print(len(triplets), triplets[:5])\n",
    "\n",
    "    # 筛选至收敛\n",
    "    triplets_selected = Select(entity_ids0, triplets, entity_limit=16, relation_limit=50)\n",
    "    while len(triplets_selected) < len(triplets):\n",
    "        triplets = triplets_selected\n",
    "        triplets_selected = Select(entity_ids0, triplets, entity_limit=16, relation_limit=50)\n",
    "        print(len(triplets_selected), len(triplets))\n",
    "\n",
    "    # 保存元组\n",
    "    entity_ids = set()\n",
    "    with gzip.open('../result/graph2step_selected.gz', 'wb') as f:\n",
    "        for triplet in triplets_selected:\n",
    "            # 保存 ID\n",
    "            entity_ids.add(triplet[0])\n",
    "            entity_ids.add(triplet[2])\n",
    "            # 加上前缀\n",
    "            triplet = ['<http://rdf.freebase.com/ns/' + triplet[0] + '>',\n",
    "                    '<http://rdf.freebase.com/ns/' + triplet[1] + '>',\n",
    "                    '<http://rdf.freebase.com/ns/' + triplet[2] + '>']\n",
    "            f.write(('\\t'.join(triplet) + '\\n').encode())\n",
    "\n",
    "    print(len(entity_ids), list(entity_ids)[:5])\n",
    "    # 保存到 pkl 文件\n",
    "    with open('../result/entity_ids2.pkl', 'wb') as f:\n",
    "        pickle.dump(entity_ids, f)\n",
    "# 大约耗时 10 分钟"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "578 1479\n",
      "ok\n"
     ]
    }
   ],
   "source": [
    "# 检验 578 个实体是否都在\n",
    "entity_ids0 = set()\n",
    "with open('../result/entity_ids0.pkl', 'rb') as f:\n",
    "    entity_ids0 = pickle.load(f)\n",
    "entity_ids2 = set()\n",
    "with open('../result/entity_ids2.pkl', 'rb') as f:\n",
    "    entity_ids2 = pickle.load(f)\n",
    "print(len(entity_ids0), len(entity_ids2))\n",
    "for entity_id in entity_ids0:\n",
    "    if entity_id not in entity_ids2:\n",
    "        print(entity_id)\n",
    "print('ok')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 添加 Tag 实体"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "578 [('m.03177r', '1291544'), ('m.027pfg', '1291545'), ('m.01d1_s', '1291546'), ('m.053xlz', '1291550'), ('m.017jd9', '1291552')]\n",
      "51798 [('id', 'tag'), ('1291543', '科幻,喜剧,人性,爱情,青春,大陆,犯罪,动作,经典,香港'), ('1291544', '惊悚,科幻,人性,青春,经典,动作,动画,美国,悬疑'), ('1291545', '科幻,喜剧,人性,文艺,悬疑,爱情,青春,经典,香港,美国,动画'), ('1291546', '人性,文艺,爱情,青春,大陆,经典,香港,美国,惊悚')]\n",
      "578 [('m.03177r', '惊悚,科幻,人性,青春,经典,动作,动画,美国,悬疑'), ('m.027pfg', '科幻,喜剧,人性,文艺,悬疑,爱情,青春,经典,香港,美国,动画'), ('m.01d1_s', '人性,文艺,爱情,青春,大陆,经典,香港,美国,惊悚'), ('m.053xlz', '喜剧,人性,文艺,爱情,青春,大陆,经典,动作,犯罪,香港,悬疑'), ('m.017jd9', '惊悚,科幻,喜剧,人性,文艺,爱情,青春,经典,动作,香港,美国,动画')]\n",
      "5161 [['m.03177r', 'has_tag', '惊悚'], ['m.03177r', 'has_tag', '科幻'], ['m.03177r', 'has_tag', '人性'], ['m.03177r', 'has_tag', '青春'], ['m.03177r', 'has_tag', '经典']]\n"
     ]
    }
   ],
   "source": [
    "# 建立实体 ID 到电影 ID 的映射\n",
    "entity_movie_map = {}\n",
    "with open('../data/douban2fb.txt', 'r') as f:\n",
    "    for line in f:\n",
    "        # 格式不统一，有的 \\t 有的空格\n",
    "        # 将 \\t 替换成空格\n",
    "        line = line.replace('\\t', ' ')\n",
    "        line = line.strip().split(' ')\n",
    "        entity_movie_map[line[1]] = line[0]\n",
    "print(len(entity_movie_map), list(entity_movie_map.items())[:5])\n",
    "\n",
    "# 建立电影 ID 到 Tag 的映射，编码为 utf-8\n",
    "movie_tag_map = {}\n",
    "with open('../data/Movie_tag.csv', 'r', encoding='utf-8') as f:\n",
    "    reader = csv.reader(f)\n",
    "    for row in reader:\n",
    "        movie_tag_map[row[0]] = row[1]\n",
    "print(len(movie_tag_map), list(movie_tag_map.items())[:5])\n",
    "\n",
    "# 建立实体 ID 到 Tag 的映射\n",
    "entity_tag_map = {}\n",
    "for entity_id in entity_movie_map:\n",
    "    movie_id = entity_movie_map[entity_id]\n",
    "    if movie_id in movie_tag_map:\n",
    "        entity_tag_map[entity_id] = movie_tag_map[movie_id]\n",
    "print(len(entity_tag_map), list(entity_tag_map.items())[:5])\n",
    "\n",
    "# 在三元组中加入 Tag\n",
    "triplets = []\n",
    "with gzip.open('../result/graph2step_selected.gz', 'rb') as f:\n",
    "    triplets = []\n",
    "    for line in f:\n",
    "        line = line.strip()\n",
    "        triplet = line.decode().split('\\t')[:3]\n",
    "        triplet = [triplet[0][28:-1], triplet[1][28:-1], triplet[2][28:-1]]\n",
    "        triplets.append(triplet)\n",
    "\n",
    "new_triplets = []\n",
    "for entity_id in entity_tag_map:\n",
    "    tags = entity_tag_map[entity_id].split(',')\n",
    "    for tag in tags:\n",
    "        new_triplets.append([entity_id, 'has_tag', tag])\n",
    "print(len(new_triplets), new_triplets[:5])\n",
    "triplets += new_triplets\n",
    "\n",
    "# 保存到文件\n",
    "with gzip.open('../result/FinalGraph.gz', 'wb') as f:\n",
    "    for triplet in triplets:\n",
    "        # 不要前缀了\n",
    "        f.write(('\\t'.join(triplet) + '\\n').encode())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
